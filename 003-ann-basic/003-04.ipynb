{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e04b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 20:19:20.882199: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/aaron/Github/Kmong/Aaron/hg-mldl2/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ê°ì • ë¶„ì„ FastAPI ì›¹ì„œë²„\n",
    "# 003-03.ipynbì—ì„œ ì €ì¥í•œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê¸ì •/ë¶€ì • ê°ì •ì„ ë¶„ì„í•˜ëŠ” ì›¹ì„œë²„\n",
    "\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.responses import HTMLResponse\n",
    "from pydantic import BaseModel\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "import uvicorn\n",
    "from typing import List, Dict\n",
    "import logging\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"ê°ì • ë¶„ì„ API\",\n",
    "    description=\"ë¦¬ë·° í…ìŠ¤íŠ¸ì˜ ê¸ì •/ë¶€ì •ì„ ë¶„ì„í•˜ëŠ” API\",\n",
    "    version=\"1.0.0\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9cff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìš”ì²­/ì‘ë‹µ ëª¨ë¸ ì •ì˜\n",
    "class TextRequest(BaseModel):\n",
    "    text: str\n",
    "    \n",
    "class TextBatchRequest(BaseModel):\n",
    "    texts: List[str]\n",
    "\n",
    "class SentimentResponse(BaseModel):\n",
    "    text: str\n",
    "    prediction: str  # \"ê¸ì •\" or \"ë¶€ì •\"\n",
    "    confidence: float  # ì‹ ë¢°ë„ (0-1)\n",
    "    probability: float  # ì›ì‹œ í™•ë¥  (0-1)\n",
    "\n",
    "class BatchSentimentResponse(BaseModel):\n",
    "    results: List[SentimentResponse]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d76b8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°ì • ë¶„ì„ ì˜ˆì¸¡ê¸° í´ë˜ìŠ¤\n",
    "class SentimentPredictor:\n",
    "    \"\"\"ê°ì • ë¶„ì„ ì˜ˆì¸¡ê¸° í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str, vectorizer_path: str, scaler_path: str):\n",
    "        \"\"\"\n",
    "        ì €ì¥ëœ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸°ë“¤ì„ ë¶ˆëŸ¬ì™€ì„œ ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            model_path: ì €ì¥ëœ Keras ëª¨ë¸ ê²½ë¡œ\n",
    "            vectorizer_path: ì €ì¥ëœ TF-IDF ë²¡í„°ë¼ì´ì € ê²½ë¡œ  \n",
    "            scaler_path: ì €ì¥ëœ StandardScaler ê²½ë¡œ\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.vectorizer_path = vectorizer_path\n",
    "        self.scaler_path = scaler_path\n",
    "        \n",
    "        # ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        self.load_components()\n",
    "    \n",
    "    def load_components(self):\n",
    "        \"\"\"ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸°ë“¤ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ\"\"\"\n",
    "        try:\n",
    "            logger.info(\"ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ë¡œë”© ì¤‘...\")\n",
    "            \n",
    "            # Keras ëª¨ë¸ ë¡œë“œ\n",
    "            self.model = load_model(self.model_path)\n",
    "            logger.info(f\"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path}\")\n",
    "            \n",
    "            # TF-IDF ë²¡í„°ë¼ì´ì € ë¡œë“œ\n",
    "            with open(self.vectorizer_path, 'rb') as f:\n",
    "                self.vectorizer = pickle.load(f)\n",
    "            logger.info(f\"TF-IDF ë²¡í„°ë¼ì´ì € ë¡œë“œ ì™„ë£Œ: {self.vectorizer_path}\")\n",
    "            \n",
    "            # StandardScaler ë¡œë“œ\n",
    "            with open(self.scaler_path, 'rb') as f:\n",
    "                self.scaler = pickle.load(f)\n",
    "            logger.info(f\"í‘œì¤€í™” ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ: {self.scaler_path}\")\n",
    "            \n",
    "            logger.info(\"ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (í›ˆë ¨ ì‹œì™€ ë™ì¼í•œ ë°©ì‹)\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "        text = str(text)\n",
    "        \n",
    "        # HTML íƒœê·¸ ì œê±°\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "        \n",
    "        # URL ì œê±°\n",
    "        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "        \n",
    "        # ì´ë©”ì¼ ì œê±°\n",
    "        text = re.sub(r'\\\\S+@\\\\S+', '', text)\n",
    "        \n",
    "        # íŠ¹ìˆ˜ë¬¸ìëŠ” ê³µë°±ìœ¼ë¡œ ëŒ€ì²´ (í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ìœ ì§€)\n",
    "        text = re.sub(r'[^ê°€-í£a-zA-Z0-9\\\\s]', ' ', text)\n",
    "        \n",
    "        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ\n",
    "        text = re.sub(r'\\\\s+', ' ', text)\n",
    "        \n",
    "        # ì•ë’¤ ê³µë°± ì œê±°\n",
    "        text = text.strip()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def predict(self, text: str) -> tuple:\n",
    "        \"\"\"\n",
    "        í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ì˜ˆì¸¡\n",
    "        \n",
    "        Args:\n",
    "            text: ì˜ˆì¸¡í•  í…ìŠ¤íŠ¸\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (ì˜ˆì¸¡ê²°ê³¼, ì‹ ë¢°ë„, ì›ì‹œí™•ë¥ )\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
    "            processed_text = self.preprocess_text(text)\n",
    "            \n",
    "            if not processed_text.strip():\n",
    "                return \"ë¶€ì •\", 0.5, 0.5  # ë¹ˆ í…ìŠ¤íŠ¸ì˜ ê²½ìš° ê¸°ë³¸ê°’\n",
    "            \n",
    "            # TF-IDF ë²¡í„°í™”\n",
    "            text_vector = self.vectorizer.transform([processed_text])\n",
    "            \n",
    "            # ì •ê·œí™”\n",
    "            text_scaled = self.scaler.transform(text_vector.toarray())\n",
    "            \n",
    "            # ì˜ˆì¸¡\n",
    "            prob = self.model.predict(text_scaled, verbose=0)[0][0]\n",
    "            prediction = \"ê¸ì •\" if prob > 0.5 else \"ë¶€ì •\"\n",
    "            confidence = prob if prob > 0.5 else (1 - prob)\n",
    "            \n",
    "            return prediction, float(confidence), float(prob)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            raise HTTPException(status_code=500, detail=f\"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "    \n",
    "    def predict_batch(self, texts: List[str]) -> List[tuple]:\n",
    "        \"\"\"\n",
    "        ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œë²ˆì— ì˜ˆì¸¡\n",
    "        \n",
    "        Args:\n",
    "            texts: ì˜ˆì¸¡í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "            \n",
    "        Returns:\n",
    "            list: [(ì˜ˆì¸¡ê²°ê³¼, ì‹ ë¢°ë„, ì›ì‹œí™•ë¥ ), ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            result = self.predict(text)\n",
    "            results.append(result)\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "088ef9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rb/qh6lstqx6_x1zhdc_b0z8h840000gn/T/ipykernel_39752/1933391706.py:29: DeprecationWarning: \n",
      "        on_event is deprecated, use lifespan event handlers instead.\n",
      "\n",
      "        Read more about it in the\n",
      "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
      "        \n",
      "  @app.on_event(\"startup\")\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì´ˆê¸°í™” (ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰)\n",
    "def initialize_model():\n",
    "    \"\"\"ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ì˜ˆì¸¡ê¸°ë¥¼ ì´ˆê¸°í™”\"\"\"\n",
    "    try:\n",
    "        # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "        model_dir = \"saved_models\"\n",
    "        model_name = \"sentiment_mlp_model_20250916_193146\"  # 003-03.ipynbì—ì„œ ì €ì¥ëœ ëª¨ë¸ëª…\n",
    "        \n",
    "        model_path = os.path.join(model_dir, f\"{model_name}.keras\")\n",
    "        vectorizer_path = os.path.join(model_dir, f\"{model_name}_vectorizer.pkl\")\n",
    "        scaler_path = os.path.join(model_dir, f\"{model_name}_scaler.pkl\")\n",
    "        \n",
    "        # íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "        if not all(os.path.exists(path) for path in [model_path, vectorizer_path, scaler_path]):\n",
    "            raise FileNotFoundError(\"ëª¨ë¸ íŒŒì¼ë“¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 003-03.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ ì €ì¥í•´ì£¼ì„¸ìš”.\")\n",
    "        \n",
    "        # ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”\n",
    "        predictor = SentimentPredictor(model_path, vectorizer_path, scaler_path)\n",
    "        logger.info(\"ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "        return predictor\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        raise\n",
    "\n",
    "# ì „ì—­ ì˜ˆì¸¡ê¸° ë³€ìˆ˜\n",
    "predictor = None\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "    \"\"\"ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "    global predictor\n",
    "    try:\n",
    "        predictor = initialize_model()\n",
    "        logger.info(\"ì„œë²„ ì‹œì‘ ì™„ë£Œ!\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "328690e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API ì—”ë“œí¬ì¸íŠ¸ë“¤\n",
    "\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "async def root():\n",
    "    \"\"\"ë©”ì¸ í˜ì´ì§€ - ê°„ë‹¨í•œ ì›¹ ì¸í„°í˜ì´ìŠ¤\"\"\"\n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"ko\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>ê°ì • ë¶„ì„ API</title>\n",
    "        <style>\n",
    "            body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }\n",
    "            .container { background: #f5f5f5; padding: 20px; border-radius: 10px; margin: 20px 0; }\n",
    "            textarea { width: 100%; height: 100px; padding: 10px; border: 1px solid #ddd; border-radius: 5px; }\n",
    "            button { background: #007bff; color: white; padding: 10px 20px; border: none; border-radius: 5px; cursor: pointer; }\n",
    "            button:hover { background: #0056b3; }\n",
    "            .result { margin-top: 20px; padding: 15px; border-radius: 5px; }\n",
    "            .positive { background: #d4edda; border: 1px solid #c3e6cb; color: #155724; }\n",
    "            .negative { background: #f8d7da; border: 1px solid #f5c6cb; color: #721c24; }\n",
    "            .example { background: #e2e3e5; padding: 10px; margin: 5px 0; border-radius: 3px; cursor: pointer; }\n",
    "            .example:hover { background: #d1d3d4; }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>ğŸ­ ê°ì • ë¶„ì„ API</h1>\n",
    "        <p>ë¦¬ë·°ë‚˜ ëŒ“ê¸€ì˜ ê°ì •ì„ ë¶„ì„í•˜ì—¬ ê¸ì •/ë¶€ì •ì„ íŒë‹¨í•©ë‹ˆë‹¤.</p>\n",
    "        \n",
    "        <div class=\"container\">\n",
    "            <h3>í…ìŠ¤íŠ¸ ì…ë ¥</h3>\n",
    "            <textarea id=\"textInput\" placeholder=\"ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”...\"></textarea>\n",
    "            <br><br>\n",
    "            <button onclick=\"analyzeSentiment()\">ê°ì • ë¶„ì„í•˜ê¸°</button>\n",
    "            <div id=\"result\"></div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"container\">\n",
    "            <h3>ì˜ˆì‹œ í…ìŠ¤íŠ¸ (í´ë¦­í•˜ì—¬ í…ŒìŠ¤íŠ¸)</h3>\n",
    "            <div class=\"example\" onclick=\"setExample('ì •ë§ ë§›ìˆì–´ìš”! ìµœê³ ì…ë‹ˆë‹¤!')\">ì •ë§ ë§›ìˆì–´ìš”! ìµœê³ ì…ë‹ˆë‹¤!</div>\n",
    "            <div class=\"example\" onclick=\"setExample('ì„œë¹„ìŠ¤ê°€ ë³„ë¡œë„¤ìš”... ì‹¤ë§ì´ì—ìš”')\">ì„œë¹„ìŠ¤ê°€ ë³„ë¡œë„¤ìš”... ì‹¤ë§ì´ì—ìš”</div>\n",
    "            <div class=\"example\" onclick=\"setExample('ê°€ê²© ëŒ€ë¹„ ê´œì°®ì€ ê²ƒ ê°™ì•„ìš”')\">ê°€ê²© ëŒ€ë¹„ ê´œì°®ì€ ê²ƒ ê°™ì•„ìš”</div>\n",
    "            <div class=\"example\" onclick=\"setExample('ì™„ì „ ìµœì•…ì´ì—ìš”. ë‹¤ì‹œëŠ” ì•ˆ ì™€ìš”')\">ì™„ì „ ìµœì•…ì´ì—ìš”. ë‹¤ì‹œëŠ” ì•ˆ ì™€ìš”</div>\n",
    "            <div class=\"example\" onclick=\"setExample('ì§ì›ë“¤ì´ ì¹œì ˆí•˜ê³  ìŒì‹ë„ ì¢‹ì•„ìš”')\">ì§ì›ë“¤ì´ ì¹œì ˆí•˜ê³  ìŒì‹ë„ ì¢‹ì•„ìš”</div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"container\">\n",
    "            <h3>API ì‚¬ìš©ë²•</h3>\n",
    "            <p><strong>ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¶„ì„:</strong> POST /predict</p>\n",
    "            <pre>{\"text\": \"ë¶„ì„í•  í…ìŠ¤íŠ¸\"}</pre>\n",
    "            \n",
    "            <p><strong>ë°°ì¹˜ ë¶„ì„:</strong> POST /predict/batch</p>\n",
    "            <pre>{\"texts\": [\"í…ìŠ¤íŠ¸1\", \"í…ìŠ¤íŠ¸2\", ...]}</pre>\n",
    "            \n",
    "            <p><strong>API ë¬¸ì„œ:</strong> <a href=\"/docs\">/docs</a></p>\n",
    "        </div>\n",
    "\n",
    "        <script>\n",
    "            function setExample(text) {\n",
    "                document.getElementById('textInput').value = text;\n",
    "            }\n",
    "            \n",
    "            async function analyzeSentiment() {\n",
    "                const text = document.getElementById('textInput').value.trim();\n",
    "                if (!text) {\n",
    "                    alert('í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.');\n",
    "                    return;\n",
    "                }\n",
    "                \n",
    "                try {\n",
    "                    const response = await fetch('/predict', {\n",
    "                        method: 'POST',\n",
    "                        headers: {\n",
    "                            'Content-Type': 'application/json',\n",
    "                        },\n",
    "                        body: JSON.stringify({text: text})\n",
    "                    });\n",
    "                    \n",
    "                    const data = await response.json();\n",
    "                    \n",
    "                    if (response.ok) {\n",
    "                        const resultClass = data.prediction === 'ê¸ì •' ? 'positive' : 'negative';\n",
    "                        document.getElementById('result').innerHTML = `\n",
    "                            <div class=\"result ${resultClass}\">\n",
    "                                <h4>ë¶„ì„ ê²°ê³¼</h4>\n",
    "                                <p><strong>ì˜ˆì¸¡:</strong> ${data.prediction}</p>\n",
    "                                <p><strong>ì‹ ë¢°ë„:</strong> ${(data.confidence * 100).toFixed(1)}%</p>\n",
    "                                <p><strong>í™•ë¥ :</strong> ${(data.probability * 100).toFixed(1)}%</p>\n",
    "                            </div>\n",
    "                        `;\n",
    "                    } else {\n",
    "                        document.getElementById('result').innerHTML = `\n",
    "                            <div class=\"result negative\">\n",
    "                                <h4>ì˜¤ë¥˜ ë°œìƒ</h4>\n",
    "                                <p>${data.detail || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}</p>\n",
    "                            </div>\n",
    "                        `;\n",
    "                    }\n",
    "                } catch (error) {\n",
    "                    document.getElementById('result').innerHTML = `\n",
    "                        <div class=\"result negative\">\n",
    "                            <h4>ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜</h4>\n",
    "                            <p>ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${error.message}</p>\n",
    "                        </div>\n",
    "                    `;\n",
    "                }\n",
    "            }\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return html_content\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"ì„œë²„ ìƒíƒœ í™•ì¸\"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"model_loaded\": predictor is not None,\n",
    "        \"message\": \"ê°ì • ë¶„ì„ APIê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9757a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°ì • ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸ë“¤\n",
    "\n",
    "@app.post(\"/predict\", response_model=SentimentResponse)\n",
    "async def predict_sentiment(request: TextRequest):\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    - **text**: ë¶„ì„í•  í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "    - **prediction**: \"ê¸ì •\" ë˜ëŠ” \"ë¶€ì •\"\n",
    "    - **confidence**: ì˜ˆì¸¡ ì‹ ë¢°ë„ (0-1)\n",
    "    - **probability**: ê¸ì •ì¼ í™•ë¥  (0-1)\n",
    "    \"\"\"\n",
    "    if predictor is None:\n",
    "        raise HTTPException(status_code=503, detail=\"ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    if not request.text.strip():\n",
    "        raise HTTPException(status_code=400, detail=\"ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    try:\n",
    "        prediction, confidence, probability = predictor.predict(request.text)\n",
    "        \n",
    "        return SentimentResponse(\n",
    "            text=request.text,\n",
    "            prediction=prediction,\n",
    "            confidence=confidence,\n",
    "            probability=probability\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=\"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "@app.post(\"/predict/batch\", response_model=BatchSentimentResponse)\n",
    "async def predict_sentiment_batch(request: TextBatchRequest):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ í•œë²ˆì— ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    - **texts**: ë¶„ì„í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "    - **results**: ê° í…ìŠ¤íŠ¸ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    if predictor is None:\n",
    "        raise HTTPException(status_code=503, detail=\"ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    if not request.texts:\n",
    "        raise HTTPException(status_code=400, detail=\"ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    if len(request.texts) > 100:  # ë°°ì¹˜ í¬ê¸° ì œí•œ\n",
    "        raise HTTPException(status_code=400, detail=\"í•œ ë²ˆì— ìµœëŒ€ 100ê°œì˜ í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    try:\n",
    "        results = []\n",
    "        batch_predictions = predictor.predict_batch(request.texts)\n",
    "        \n",
    "        for text, (prediction, confidence, probability) in zip(request.texts, batch_predictions):\n",
    "            results.append(SentimentResponse(\n",
    "                text=text,\n",
    "                prediction=prediction,\n",
    "                confidence=confidence,\n",
    "                probability=probability\n",
    "            ))\n",
    "        \n",
    "        return BatchSentimentResponse(results=results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"ë°°ì¹˜ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=\"ë°°ì¹˜ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "@app.get(\"/model/info\")\n",
    "async def get_model_info():\n",
    "    \"\"\"ëª¨ë¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    if predictor is None:\n",
    "        raise HTTPException(status_code=503, detail=\"ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    return {\n",
    "        \"model_name\": \"ê°ì • ë¶„ì„ MLP ëª¨ë¸\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"model_file\": os.path.basename(predictor.model_path),\n",
    "        \"vectorizer_file\": os.path.basename(predictor.vectorizer_path),\n",
    "        \"scaler_file\": os.path.basename(predictor.scaler_path),\n",
    "        \"total_parameters\": predictor.model.count_params(),\n",
    "        \"input_features\": predictor.model.input_shape[1],\n",
    "        \"classes\": [\"ë¶€ì •\", \"ê¸ì •\"],\n",
    "        \"description\": \"TF-IDF + MLP ê¸°ë°˜ í•œêµ­ì–´ ê°ì • ë¶„ì„ ëª¨ë¸\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deed6cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Jupyter í™˜ê²½ ê°ì§€ë¨\n",
      "ğŸš€ ê°ì • ë¶„ì„ FastAPI ì„œë²„ ì‹œì‘! (Jupyter ëª¨ë“œ)\n",
      "ğŸ“ ì£¼ì†Œ: http://127.0.0.1:8000\n",
      "ğŸ“– API ë¬¸ì„œ: http://127.0.0.1:8000/docs\n",
      "ğŸ­ ì›¹ ì¸í„°í˜ì´ìŠ¤: http://127.0.0.1:8000\n",
      "â¤ï¸ ìƒíƒœ í™•ì¸: http://127.0.0.1:8000/health\n",
      "\n",
      "ì„œë²„ë¥¼ ì¤‘ì§€í•˜ë ¤ë©´ Kernel -> Interruptë¥¼ ì„ íƒí•˜ì„¸ìš”.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [39752]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:__main__:ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ë¡œë”© ì¤‘...\n",
      "INFO:__main__:ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: saved_models/sentiment_mlp_model_20250916_193146.keras\n",
      "INFO:__main__:TF-IDF ë²¡í„°ë¼ì´ì € ë¡œë“œ ì™„ë£Œ: saved_models/sentiment_mlp_model_20250916_193146_vectorizer.pkl\n",
      "INFO:__main__:í‘œì¤€í™” ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ: saved_models/sentiment_mlp_model_20250916_193146_scaler.pkl\n",
      "INFO:__main__:ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì™„ë£Œ!\n",
      "INFO:__main__:ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!\n",
      "INFO:__main__:ì„œë²„ ì‹œì‘ ì™„ë£Œ!\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:63646 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:63646 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:63646 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:63646 - \"POST /predict HTTP/1.1\" 200 OK\n",
      "\n",
      "ğŸ›‘ ì„œë²„ ì¤‘ì§€ ìš”ì²­ë¨\n"
     ]
    }
   ],
   "source": [
    "# Jupyter ë…¸íŠ¸ë¶ìš© ì„œë²„ ì‹¤í–‰ í•¨ìˆ˜\n",
    "import asyncio\n",
    "import threading\n",
    "import time\n",
    "from contextlib import asynccontextmanager\n",
    "\n",
    "def run_server_jupyter(host: str = \"127.0.0.1\", port: int = 8000):\n",
    "    \"\"\"\n",
    "    Jupyter ë…¸íŠ¸ë¶ì—ì„œ FastAPI ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        host: ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: 127.0.0.1)\n",
    "        port: ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 8000)\n",
    "    \"\"\"\n",
    "    print(f\"ğŸš€ ê°ì • ë¶„ì„ FastAPI ì„œë²„ ì‹œì‘! (Jupyter ëª¨ë“œ)\")\n",
    "    print(f\"ğŸ“ ì£¼ì†Œ: http://{host}:{port}\")\n",
    "    print(f\"ğŸ“– API ë¬¸ì„œ: http://{host}:{port}/docs\")\n",
    "    print(f\"ğŸ­ ì›¹ ì¸í„°í˜ì´ìŠ¤: http://{host}:{port}\")\n",
    "    print(f\"â¤ï¸ ìƒíƒœ í™•ì¸: http://{host}:{port}/health\")\n",
    "    print()\n",
    "    print(\"ì„œë²„ë¥¼ ì¤‘ì§€í•˜ë ¤ë©´ Kernel -> Interruptë¥¼ ì„ íƒí•˜ì„¸ìš”.\")\n",
    "    \n",
    "    # Jupyterì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì„œë²„ ì‹¤í–‰\n",
    "    def run_uvicorn():\n",
    "        import asyncio\n",
    "        import uvicorn\n",
    "        \n",
    "        # ìƒˆë¡œìš´ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        \n",
    "        config = uvicorn.Config(\n",
    "            app=app,\n",
    "            host=host,\n",
    "            port=port,\n",
    "            log_level=\"info\"\n",
    "        )\n",
    "        server = uvicorn.Server(config)\n",
    "        \n",
    "        try:\n",
    "            loop.run_until_complete(server.serve())\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nğŸ›‘ ì„œë²„ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        finally:\n",
    "            loop.close()\n",
    "    \n",
    "    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì„œë²„ ì‹¤í–‰\n",
    "    server_thread = threading.Thread(target=run_uvicorn, daemon=True)\n",
    "    server_thread.start()\n",
    "    \n",
    "    try:\n",
    "        # ë©”ì¸ ìŠ¤ë ˆë“œëŠ” ì„œë²„ ìŠ¤ë ˆë“œê°€ ì‚´ì•„ìˆëŠ” ë™ì•ˆ ëŒ€ê¸°\n",
    "        while server_thread.is_alive():\n",
    "            time.sleep(0.1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nğŸ›‘ ì„œë²„ ì¤‘ì§€ ìš”ì²­ë¨\")\n",
    "    \n",
    "    return server_thread\n",
    "\n",
    "# ì¼ë°˜ Python ìŠ¤í¬ë¦½íŠ¸ìš© ì„œë²„ ì‹¤í–‰ í•¨ìˆ˜\n",
    "def run_server_script(host: str = \"127.0.0.1\", port: int = 8000, reload: bool = False):\n",
    "    \"\"\"\n",
    "    ì¼ë°˜ Python ìŠ¤í¬ë¦½íŠ¸ì—ì„œ FastAPI ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        host: ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: 127.0.0.1)\n",
    "        port: ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 8000)\n",
    "        reload: ì½”ë“œ ë³€ê²½ ì‹œ ìë™ ì¬ì‹œì‘ (ê¸°ë³¸ê°’: False)\n",
    "    \"\"\"\n",
    "    print(f\"ğŸš€ ê°ì • ë¶„ì„ FastAPI ì„œë²„ ì‹œì‘!\")\n",
    "    print(f\"ğŸ“ ì£¼ì†Œ: http://{host}:{port}\")\n",
    "    print(f\"ğŸ“– API ë¬¸ì„œ: http://{host}:{port}/docs\")\n",
    "    print(f\"ğŸ­ ì›¹ ì¸í„°í˜ì´ìŠ¤: http://{host}:{port}\")\n",
    "    print(f\"â¤ï¸ ìƒíƒœ í™•ì¸: http://{host}:{port}/health\")\n",
    "    print()\n",
    "    print(\"ì„œë²„ë¥¼ ì¤‘ì§€í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\")\n",
    "    \n",
    "    uvicorn.run(\n",
    "        app,  # app ê°ì²´ ì§ì ‘ ì „ë‹¬\n",
    "        host=host,\n",
    "        port=port,\n",
    "        reload=reload,\n",
    "        log_level=\"info\"\n",
    "    )\n",
    "\n",
    "# í™˜ê²½ ê°ì§€ ë° ì ì ˆí•œ ì‹¤í–‰ í•¨ìˆ˜ ì„ íƒ\n",
    "def run_server(host: str = \"127.0.0.1\", port: int = 8000, reload: bool = False):\n",
    "    \"\"\"\n",
    "    í™˜ê²½ì„ ìë™ ê°ì§€í•˜ì—¬ ì ì ˆí•œ ë°©ì‹ìœ¼ë¡œ ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Jupyter í™˜ê²½ì¸ì§€ í™•ì¸\n",
    "        get_ipython()\n",
    "        print(\"ğŸ” Jupyter í™˜ê²½ ê°ì§€ë¨\")\n",
    "        return run_server_jupyter(host, port)\n",
    "    except NameError:\n",
    "        # ì¼ë°˜ Python ìŠ¤í¬ë¦½íŠ¸ í™˜ê²½\n",
    "        print(\"ğŸ” Python ìŠ¤í¬ë¦½íŠ¸ í™˜ê²½ ê°ì§€ë¨\")\n",
    "        return run_server_script(host, port, reload)\n",
    "\n",
    "# ë©”ì¸ ì‹¤í–‰ë¶€ (Jupyterì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)\n",
    "if __name__ == \"__main__\":\n",
    "    # ì„œë²„ ì‹¤í–‰ (ê¸°ë³¸ ì„¤ì •)\n",
    "    run_server()\n",
    "    \n",
    "    # ë‹¤ë¥¸ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰í•˜ë ¤ë©´:\n",
    "    # run_server(host=\"0.0.0.0\", port=8080, reload=True)  # ì™¸ë¶€ ì ‘ê·¼ í—ˆìš©, í¬íŠ¸ 8080, ìë™ ì¬ì‹œì‘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a420de",
   "metadata": {},
   "source": [
    "# ğŸš€ FastAPI ê°ì • ë¶„ì„ ì›¹ì„œë²„ ì‚¬ìš© ê°€ì´ë“œ\n",
    "\n",
    "## ğŸ“‹ ê°œìš”\n",
    "003-03.ipynbì—ì„œ í›ˆë ¨í•˜ê³  ì €ì¥í•œ MLP ê°ì • ë¶„ì„ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” FastAPI ì›¹ì„œë²„ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ› ï¸ ì„¤ì¹˜ ë° ì‹¤í–‰\n",
    "\n",
    "### 1. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "```bash\n",
    "pip install fastapi uvicorn tensorflow scikit-learn pandas numpy\n",
    "```\n",
    "\n",
    "### 2. ì„œë²„ ì‹¤í–‰ ë°©ë²•\n",
    "\n",
    "#### ë°©ë²• 1: Jupyter ë…¸íŠ¸ë¶ì—ì„œ ì§ì ‘ ì‹¤í–‰\n",
    "ìœ„ì˜ ëª¨ë“  ì…€ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•œ í›„, ë§ˆì§€ë§‰ ì…€ì„ ì‹¤í–‰í•˜ë©´ ì„œë²„ê°€ ì‹œì‘ë©ë‹ˆë‹¤.\n",
    "\n",
    "#### ë°©ë²• 2: Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ì €ì¥í•˜ì—¬ ì‹¤í–‰\n",
    "ë…¸íŠ¸ë¶ì„ `.py` íŒŒì¼ë¡œ ë‚´ë³´ë‚¸ í›„ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰:\n",
    "```bash\n",
    "python sentiment_api.py\n",
    "```\n",
    "\n",
    "#### ë°©ë²• 3: uvicornìœ¼ë¡œ ì§ì ‘ ì‹¤í–‰\n",
    "```bash\n",
    "uvicorn main:app --host 127.0.0.1 --port 8000 --reload\n",
    "```\n",
    "\n",
    "## ğŸŒ API ì—”ë“œí¬ì¸íŠ¸\n",
    "\n",
    "### ë©”ì¸ í˜ì´ì§€\n",
    "- **URL**: `http://127.0.0.1:8000/`\n",
    "- **ì„¤ëª…**: ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì—¬ ê°ì • ë¶„ì„ ê°€ëŠ¥\n",
    "\n",
    "### ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¶„ì„\n",
    "- **URL**: `POST http://127.0.0.1:8000/predict`\n",
    "- **ìš”ì²­ í˜•ì‹**:\n",
    "```json\n",
    "{\n",
    "    \"text\": \"ì •ë§ ë§›ìˆì–´ìš”! ìµœê³ ì…ë‹ˆë‹¤!\"\n",
    "}\n",
    "```\n",
    "- **ì‘ë‹µ í˜•ì‹**:\n",
    "```json\n",
    "{\n",
    "    \"text\": \"ì •ë§ ë§›ìˆì–´ìš”! ìµœê³ ì…ë‹ˆë‹¤!\",\n",
    "    \"prediction\": \"ê¸ì •\",\n",
    "    \"confidence\": 0.999,\n",
    "    \"probability\": 0.999\n",
    "}\n",
    "```\n",
    "\n",
    "### ë°°ì¹˜ í…ìŠ¤íŠ¸ ë¶„ì„\n",
    "- **URL**: `POST http://127.0.0.1:8000/predict/batch`\n",
    "- **ìš”ì²­ í˜•ì‹**:\n",
    "```json\n",
    "{\n",
    "    \"texts\": [\n",
    "        \"ì •ë§ ë§›ìˆì–´ìš”!\",\n",
    "        \"ì„œë¹„ìŠ¤ê°€ ë³„ë¡œë„¤ìš”...\",\n",
    "        \"ê°€ê²© ëŒ€ë¹„ ê´œì°®ì•„ìš”\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "### ëª¨ë¸ ì •ë³´\n",
    "- **URL**: `GET http://127.0.0.1:8000/model/info`\n",
    "- **ì„¤ëª…**: ë¡œë“œëœ ëª¨ë¸ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ\n",
    "\n",
    "### ìƒíƒœ í™•ì¸\n",
    "- **URL**: `GET http://127.0.0.1:8000/health`\n",
    "- **ì„¤ëª…**: ì„œë²„ ë° ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸\n",
    "\n",
    "### API ë¬¸ì„œ\n",
    "- **URL**: `http://127.0.0.1:8000/docs`\n",
    "- **ì„¤ëª…**: ìë™ ìƒì„±ëœ Swagger UI API ë¬¸ì„œ\n",
    "\n",
    "## ğŸ§ª í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ\n",
    "\n",
    "### curlì„ ì‚¬ìš©í•œ í…ŒìŠ¤íŠ¸\n",
    "```bash\n",
    "# ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¶„ì„\n",
    "curl -X POST \"http://127.0.0.1:8000/predict\" \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"text\": \"ì •ë§ ë§›ìˆì–´ìš”!\"}'\n",
    "\n",
    "# ìƒíƒœ í™•ì¸\n",
    "curl -X GET \"http://127.0.0.1:8000/health\"\n",
    "```\n",
    "\n",
    "### Python requestsë¥¼ ì‚¬ìš©í•œ í…ŒìŠ¤íŠ¸\n",
    "```python\n",
    "import requests\n",
    "\n",
    "# ë‹¨ì¼ ì˜ˆì¸¡\n",
    "response = requests.post(\n",
    "    \"http://127.0.0.1:8000/predict\",\n",
    "    json={\"text\": \"ì •ë§ ë§›ìˆì–´ìš”!\"}\n",
    ")\n",
    "print(response.json())\n",
    "\n",
    "# ë°°ì¹˜ ì˜ˆì¸¡\n",
    "response = requests.post(\n",
    "    \"http://127.0.0.1:8000/predict/batch\",\n",
    "    json={\"texts\": [\"ì¢‹ì•„ìš”!\", \"ë³„ë¡œë„¤ìš”...\"]}\n",
    ")\n",
    "print(response.json())\n",
    "```\n",
    "\n",
    "## âš ï¸ ì£¼ì˜ì‚¬í•­\n",
    "1. **ëª¨ë¸ íŒŒì¼ ìœ„ì¹˜**: `saved_models/` ë””ë ‰í† ë¦¬ì— 003-03.ipynbì—ì„œ ì €ì¥í•œ ëª¨ë¸ íŒŒì¼ë“¤ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "2. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: TensorFlow ëª¨ë¸ì´ ë¡œë“œë˜ë¯€ë¡œ ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "3. **í¬íŠ¸ ì¶©ëŒ**: 8000ë²ˆ í¬íŠ¸ê°€ ì‚¬ìš© ì¤‘ì¸ ê²½ìš° ë‹¤ë¥¸ í¬íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "\n",
    "## ğŸ”§ ë¬¸ì œ í•´ê²°\n",
    "- **ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨**: 003-03.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ ì €ì¥í–ˆëŠ”ì§€ í™•ì¸\n",
    "- **í¬íŠ¸ ì‚¬ìš© ì¤‘**: `run_server(port=8080)` ë“±ìœ¼ë¡œ ë‹¤ë¥¸ í¬íŠ¸ ì‚¬ìš©\n",
    "- **ë©”ëª¨ë¦¬ ë¶€ì¡±**: ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•˜ê³  ì¬ì‹œë„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d26238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„œë²„ ì‹¤í–‰ (ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´ FastAPI ì„œë²„ê°€ ì‹œì‘ë©ë‹ˆë‹¤)\n",
    "# ì£¼ì˜: ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´ ì„œë²„ê°€ ì‹œì‘ë˜ê³  ì…€ì´ ê³„ì† ì‹¤í–‰ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "# ì„œë²„ë¥¼ ì¤‘ì§€í•˜ë ¤ë©´ Kernel -> Interruptë¥¼ ì„ íƒí•˜ì„¸ìš”.\n",
    "\n",
    "print(\"ğŸ”§ ì„œë²„ ì‹¤í–‰ ì¤€ë¹„ ì¤‘...\")\n",
    "print(\"ğŸ“ ëª¨ë¸ íŒŒì¼ í™•ì¸ ì¤‘...\")\n",
    "\n",
    "# ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "model_dir = \"saved_models\"\n",
    "model_name = \"sentiment_mlp_model_20250916_193146\"\n",
    "\n",
    "model_files = [\n",
    "    f\"{model_name}.keras\",\n",
    "    f\"{model_name}_vectorizer.pkl\", \n",
    "    f\"{model_name}_scaler.pkl\"\n",
    "]\n",
    "\n",
    "missing_files = []\n",
    "for file in model_files:\n",
    "    file_path = os.path.join(model_dir, file)\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"âœ… {file}\")\n",
    "    else:\n",
    "        print(f\"âŒ {file}\")\n",
    "        missing_files.append(file)\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\nâš ï¸ ëˆ„ë½ëœ íŒŒì¼ë“¤: {missing_files}\")\n",
    "    print(\"ğŸ’¡ 003-03.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ ì €ì¥í•´ì£¼ì„¸ìš”.\")\n",
    "else:\n",
    "    print(f\"\\nğŸ‰ ëª¨ë“  ëª¨ë¸ íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸš€ FastAPI ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    print()\n",
    "    \n",
    "    # ì„œë²„ ì‹¤í–‰ (Jupyter í™˜ê²½ ìë™ ê°ì§€)\n",
    "    try:\n",
    "        server_thread = run_server(host=\"127.0.0.1\", port=8000)\n",
    "        print(\"\\nâœ… ì„œë²„ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤!\")\n",
    "        print(\"ğŸŒ ë¸Œë¼ìš°ì €ì—ì„œ http://127.0.0.1:8000 ì— ì ‘ì†í•˜ì„¸ìš”!\")\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nğŸ›‘ ì„œë²„ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ì„œë²„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        print(\"ğŸ’¡ ë¬¸ì œ í•´ê²° ë°©ë²•:\")\n",
    "        print(\"   1. í¬íŠ¸ê°€ ì´ë¯¸ ì‚¬ìš© ì¤‘ì¸ ê²½ìš°: run_server(port=8080)\")\n",
    "        print(\"   2. ëª¨ë¸ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°: 003-03.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰\")\n",
    "        print(\"   3. íŒ¨í‚¤ì§€ê°€ ì—†ëŠ” ê²½ìš°: pip install -r requirements.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4fd624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„œë²„ ìƒíƒœ í™•ì¸ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤\n",
    "\n",
    "def check_server_status(host=\"127.0.0.1\", port=8000):\n",
    "    \"\"\"ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.\"\"\"\n",
    "    import requests\n",
    "    try:\n",
    "        response = requests.get(f\"http://{host}:{port}/health\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"âœ… ì„œë²„ê°€ ì •ìƒ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤! (http://{host}:{port})\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âš ï¸ ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}\")\n",
    "            return False\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_sentiment_api(text=\"ì •ë§ ë§›ìˆì–´ìš”!\", host=\"127.0.0.1\", port=8000):\n",
    "    \"\"\"ê°ì • ë¶„ì„ APIë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\"\"\"\n",
    "    import requests\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"http://{host}:{port}/predict\",\n",
    "            json={\"text\": text},\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"ğŸ“ ì…ë ¥: \\\"{text}\\\"\")\n",
    "            print(f\"ğŸ¯ ì˜ˆì¸¡: {result['prediction']}\")\n",
    "            print(f\"ğŸ“Š ì‹ ë¢°ë„: {result['confidence']:.3f}\")\n",
    "            print(f\"ğŸ“ˆ í™•ë¥ : {result['probability']:.3f}\")\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"âŒ API ì˜¤ë¥˜: {response.status_code}\")\n",
    "            print(f\"ì˜¤ë¥˜ ë‚´ìš©: {response.text}\")\n",
    "            return None\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ API ìš”ì²­ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ:\n",
    "# check_server_status()  # ì„œë²„ ìƒíƒœ í™•ì¸\n",
    "# test_sentiment_api(\"ì •ë§ ë§›ìˆì–´ìš”!\")  # ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
