{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e04b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 20:19:20.882199: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/aaron/Github/Kmong/Aaron/hg-mldl2/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 감정 분석 FastAPI 웹서버\n",
    "# 003-03.ipynb에서 저장한 모델을 사용하여 긍정/부정 감정을 분석하는 웹서버\n",
    "\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.responses import HTMLResponse\n",
    "from pydantic import BaseModel\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "import uvicorn\n",
    "from typing import List, Dict\n",
    "import logging\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"감정 분석 API\",\n",
    "    description=\"리뷰 텍스트의 긍정/부정을 분석하는 API\",\n",
    "    version=\"1.0.0\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9cff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요청/응답 모델 정의\n",
    "class TextRequest(BaseModel):\n",
    "    text: str\n",
    "    \n",
    "class TextBatchRequest(BaseModel):\n",
    "    texts: List[str]\n",
    "\n",
    "class SentimentResponse(BaseModel):\n",
    "    text: str\n",
    "    prediction: str  # \"긍정\" or \"부정\"\n",
    "    confidence: float  # 신뢰도 (0-1)\n",
    "    probability: float  # 원시 확률 (0-1)\n",
    "\n",
    "class BatchSentimentResponse(BaseModel):\n",
    "    results: List[SentimentResponse]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d76b8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 분석 예측기 클래스\n",
    "class SentimentPredictor:\n",
    "    \"\"\"감정 분석 예측기 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str, vectorizer_path: str, scaler_path: str):\n",
    "        \"\"\"\n",
    "        저장된 모델과 전처리기들을 불러와서 초기화\n",
    "        \n",
    "        Args:\n",
    "            model_path: 저장된 Keras 모델 경로\n",
    "            vectorizer_path: 저장된 TF-IDF 벡터라이저 경로  \n",
    "            scaler_path: 저장된 StandardScaler 경로\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.vectorizer_path = vectorizer_path\n",
    "        self.scaler_path = scaler_path\n",
    "        \n",
    "        # 모델과 전처리기 불러오기\n",
    "        self.load_components()\n",
    "    \n",
    "    def load_components(self):\n",
    "        \"\"\"모델과 전처리기들을 메모리에 로드\"\"\"\n",
    "        try:\n",
    "            logger.info(\"모델 및 전처리기 로딩 중...\")\n",
    "            \n",
    "            # Keras 모델 로드\n",
    "            self.model = load_model(self.model_path)\n",
    "            logger.info(f\"모델 로드 완료: {self.model_path}\")\n",
    "            \n",
    "            # TF-IDF 벡터라이저 로드\n",
    "            with open(self.vectorizer_path, 'rb') as f:\n",
    "                self.vectorizer = pickle.load(f)\n",
    "            logger.info(f\"TF-IDF 벡터라이저 로드 완료: {self.vectorizer_path}\")\n",
    "            \n",
    "            # StandardScaler 로드\n",
    "            with open(self.scaler_path, 'rb') as f:\n",
    "                self.scaler = pickle.load(f)\n",
    "            logger.info(f\"표준화 스케일러 로드 완료: {self.scaler_path}\")\n",
    "            \n",
    "            logger.info(\"모든 컴포넌트 로드 완료!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"로딩 중 오류 발생: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        텍스트 전처리 (훈련 시와 동일한 방식)\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # 문자열로 변환\n",
    "        text = str(text)\n",
    "        \n",
    "        # HTML 태그 제거\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "        \n",
    "        # URL 제거\n",
    "        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "        \n",
    "        # 이메일 제거\n",
    "        text = re.sub(r'\\\\S+@\\\\S+', '', text)\n",
    "        \n",
    "        # 특수문자는 공백으로 대체 (한글, 영문, 숫자만 유지)\n",
    "        text = re.sub(r'[^가-힣a-zA-Z0-9\\\\s]', ' ', text)\n",
    "        \n",
    "        # 연속된 공백을 하나로\n",
    "        text = re.sub(r'\\\\s+', ' ', text)\n",
    "        \n",
    "        # 앞뒤 공백 제거\n",
    "        text = text.strip()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def predict(self, text: str) -> tuple:\n",
    "        \"\"\"\n",
    "        텍스트의 감정을 예측\n",
    "        \n",
    "        Args:\n",
    "            text: 예측할 텍스트\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (예측결과, 신뢰도, 원시확률)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 텍스트 전처리\n",
    "            processed_text = self.preprocess_text(text)\n",
    "            \n",
    "            if not processed_text.strip():\n",
    "                return \"부정\", 0.5, 0.5  # 빈 텍스트의 경우 기본값\n",
    "            \n",
    "            # TF-IDF 벡터화\n",
    "            text_vector = self.vectorizer.transform([processed_text])\n",
    "            \n",
    "            # 정규화\n",
    "            text_scaled = self.scaler.transform(text_vector.toarray())\n",
    "            \n",
    "            # 예측\n",
    "            prob = self.model.predict(text_scaled, verbose=0)[0][0]\n",
    "            prediction = \"긍정\" if prob > 0.5 else \"부정\"\n",
    "            confidence = prob if prob > 0.5 else (1 - prob)\n",
    "            \n",
    "            return prediction, float(confidence), float(prob)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"예측 중 오류 발생: {e}\")\n",
    "            raise HTTPException(status_code=500, detail=f\"예측 중 오류 발생: {str(e)}\")\n",
    "    \n",
    "    def predict_batch(self, texts: List[str]) -> List[tuple]:\n",
    "        \"\"\"\n",
    "        여러 텍스트를 한번에 예측\n",
    "        \n",
    "        Args:\n",
    "            texts: 예측할 텍스트 리스트\n",
    "            \n",
    "        Returns:\n",
    "            list: [(예측결과, 신뢰도, 원시확률), ...] 형태의 리스트\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            result = self.predict(text)\n",
    "            results.append(result)\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "088ef9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rb/qh6lstqx6_x1zhdc_b0z8h840000gn/T/ipykernel_39752/1933391706.py:29: DeprecationWarning: \n",
      "        on_event is deprecated, use lifespan event handlers instead.\n",
      "\n",
      "        Read more about it in the\n",
      "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
      "        \n",
      "  @app.on_event(\"startup\")\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화 (서버 시작 시 한 번만 실행)\n",
    "def initialize_model():\n",
    "    \"\"\"저장된 모델 파일들을 찾아서 예측기를 초기화\"\"\"\n",
    "    try:\n",
    "        # 모델 파일 경로 설정\n",
    "        model_dir = \"saved_models\"\n",
    "        model_name = \"sentiment_mlp_model_20250916_193146\"  # 003-03.ipynb에서 저장된 모델명\n",
    "        \n",
    "        model_path = os.path.join(model_dir, f\"{model_name}.keras\")\n",
    "        vectorizer_path = os.path.join(model_dir, f\"{model_name}_vectorizer.pkl\")\n",
    "        scaler_path = os.path.join(model_dir, f\"{model_name}_scaler.pkl\")\n",
    "        \n",
    "        # 파일 존재 확인\n",
    "        if not all(os.path.exists(path) for path in [model_path, vectorizer_path, scaler_path]):\n",
    "            raise FileNotFoundError(\"모델 파일들을 찾을 수 없습니다. 003-03.ipynb를 먼저 실행하여 모델을 저장해주세요.\")\n",
    "        \n",
    "        # 예측기 초기화\n",
    "        predictor = SentimentPredictor(model_path, vectorizer_path, scaler_path)\n",
    "        logger.info(\"모델 초기화 완료!\")\n",
    "        return predictor\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"모델 초기화 실패: {e}\")\n",
    "        raise\n",
    "\n",
    "# 전역 예측기 변수\n",
    "predictor = None\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "    \"\"\"서버 시작 시 모델 로드\"\"\"\n",
    "    global predictor\n",
    "    try:\n",
    "        predictor = initialize_model()\n",
    "        logger.info(\"서버 시작 완료!\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"서버 시작 실패: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "328690e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 엔드포인트들\n",
    "\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "async def root():\n",
    "    \"\"\"메인 페이지 - 간단한 웹 인터페이스\"\"\"\n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"ko\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>감정 분석 API</title>\n",
    "        <style>\n",
    "            body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }\n",
    "            .container { background: #f5f5f5; padding: 20px; border-radius: 10px; margin: 20px 0; }\n",
    "            textarea { width: 100%; height: 100px; padding: 10px; border: 1px solid #ddd; border-radius: 5px; }\n",
    "            button { background: #007bff; color: white; padding: 10px 20px; border: none; border-radius: 5px; cursor: pointer; }\n",
    "            button:hover { background: #0056b3; }\n",
    "            .result { margin-top: 20px; padding: 15px; border-radius: 5px; }\n",
    "            .positive { background: #d4edda; border: 1px solid #c3e6cb; color: #155724; }\n",
    "            .negative { background: #f8d7da; border: 1px solid #f5c6cb; color: #721c24; }\n",
    "            .example { background: #e2e3e5; padding: 10px; margin: 5px 0; border-radius: 3px; cursor: pointer; }\n",
    "            .example:hover { background: #d1d3d4; }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>🎭 감정 분석 API</h1>\n",
    "        <p>리뷰나 댓글의 감정을 분석하여 긍정/부정을 판단합니다.</p>\n",
    "        \n",
    "        <div class=\"container\">\n",
    "            <h3>텍스트 입력</h3>\n",
    "            <textarea id=\"textInput\" placeholder=\"분석할 텍스트를 입력하세요...\"></textarea>\n",
    "            <br><br>\n",
    "            <button onclick=\"analyzeSentiment()\">감정 분석하기</button>\n",
    "            <div id=\"result\"></div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"container\">\n",
    "            <h3>예시 텍스트 (클릭하여 테스트)</h3>\n",
    "            <div class=\"example\" onclick=\"setExample('정말 맛있어요! 최고입니다!')\">정말 맛있어요! 최고입니다!</div>\n",
    "            <div class=\"example\" onclick=\"setExample('서비스가 별로네요... 실망이에요')\">서비스가 별로네요... 실망이에요</div>\n",
    "            <div class=\"example\" onclick=\"setExample('가격 대비 괜찮은 것 같아요')\">가격 대비 괜찮은 것 같아요</div>\n",
    "            <div class=\"example\" onclick=\"setExample('완전 최악이에요. 다시는 안 와요')\">완전 최악이에요. 다시는 안 와요</div>\n",
    "            <div class=\"example\" onclick=\"setExample('직원들이 친절하고 음식도 좋아요')\">직원들이 친절하고 음식도 좋아요</div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"container\">\n",
    "            <h3>API 사용법</h3>\n",
    "            <p><strong>단일 텍스트 분석:</strong> POST /predict</p>\n",
    "            <pre>{\"text\": \"분석할 텍스트\"}</pre>\n",
    "            \n",
    "            <p><strong>배치 분석:</strong> POST /predict/batch</p>\n",
    "            <pre>{\"texts\": [\"텍스트1\", \"텍스트2\", ...]}</pre>\n",
    "            \n",
    "            <p><strong>API 문서:</strong> <a href=\"/docs\">/docs</a></p>\n",
    "        </div>\n",
    "\n",
    "        <script>\n",
    "            function setExample(text) {\n",
    "                document.getElementById('textInput').value = text;\n",
    "            }\n",
    "            \n",
    "            async function analyzeSentiment() {\n",
    "                const text = document.getElementById('textInput').value.trim();\n",
    "                if (!text) {\n",
    "                    alert('텍스트를 입력해주세요.');\n",
    "                    return;\n",
    "                }\n",
    "                \n",
    "                try {\n",
    "                    const response = await fetch('/predict', {\n",
    "                        method: 'POST',\n",
    "                        headers: {\n",
    "                            'Content-Type': 'application/json',\n",
    "                        },\n",
    "                        body: JSON.stringify({text: text})\n",
    "                    });\n",
    "                    \n",
    "                    const data = await response.json();\n",
    "                    \n",
    "                    if (response.ok) {\n",
    "                        const resultClass = data.prediction === '긍정' ? 'positive' : 'negative';\n",
    "                        document.getElementById('result').innerHTML = `\n",
    "                            <div class=\"result ${resultClass}\">\n",
    "                                <h4>분석 결과</h4>\n",
    "                                <p><strong>예측:</strong> ${data.prediction}</p>\n",
    "                                <p><strong>신뢰도:</strong> ${(data.confidence * 100).toFixed(1)}%</p>\n",
    "                                <p><strong>확률:</strong> ${(data.probability * 100).toFixed(1)}%</p>\n",
    "                            </div>\n",
    "                        `;\n",
    "                    } else {\n",
    "                        document.getElementById('result').innerHTML = `\n",
    "                            <div class=\"result negative\">\n",
    "                                <h4>오류 발생</h4>\n",
    "                                <p>${data.detail || '알 수 없는 오류가 발생했습니다.'}</p>\n",
    "                            </div>\n",
    "                        `;\n",
    "                    }\n",
    "                } catch (error) {\n",
    "                    document.getElementById('result').innerHTML = `\n",
    "                        <div class=\"result negative\">\n",
    "                            <h4>네트워크 오류</h4>\n",
    "                            <p>서버에 연결할 수 없습니다: ${error.message}</p>\n",
    "                        </div>\n",
    "                    `;\n",
    "                }\n",
    "            }\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return html_content\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"서버 상태 확인\"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"model_loaded\": predictor is not None,\n",
    "        \"message\": \"감정 분석 API가 정상 작동 중입니다.\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9757a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 분석 API 엔드포인트들\n",
    "\n",
    "@app.post(\"/predict\", response_model=SentimentResponse)\n",
    "async def predict_sentiment(request: TextRequest):\n",
    "    \"\"\"\n",
    "    단일 텍스트의 감정을 분석합니다.\n",
    "    \n",
    "    - **text**: 분석할 텍스트\n",
    "    \n",
    "    Returns:\n",
    "    - **prediction**: \"긍정\" 또는 \"부정\"\n",
    "    - **confidence**: 예측 신뢰도 (0-1)\n",
    "    - **probability**: 긍정일 확률 (0-1)\n",
    "    \"\"\"\n",
    "    if predictor is None:\n",
    "        raise HTTPException(status_code=503, detail=\"모델이 로드되지 않았습니다.\")\n",
    "    \n",
    "    if not request.text.strip():\n",
    "        raise HTTPException(status_code=400, detail=\"빈 텍스트는 분석할 수 없습니다.\")\n",
    "    \n",
    "    try:\n",
    "        prediction, confidence, probability = predictor.predict(request.text)\n",
    "        \n",
    "        return SentimentResponse(\n",
    "            text=request.text,\n",
    "            prediction=prediction,\n",
    "            confidence=confidence,\n",
    "            probability=probability\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"예측 중 오류: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=\"예측 중 오류가 발생했습니다.\")\n",
    "\n",
    "@app.post(\"/predict/batch\", response_model=BatchSentimentResponse)\n",
    "async def predict_sentiment_batch(request: TextBatchRequest):\n",
    "    \"\"\"\n",
    "    여러 텍스트의 감정을 한번에 분석합니다.\n",
    "    \n",
    "    - **texts**: 분석할 텍스트 리스트\n",
    "    \n",
    "    Returns:\n",
    "    - **results**: 각 텍스트에 대한 분석 결과 리스트\n",
    "    \"\"\"\n",
    "    if predictor is None:\n",
    "        raise HTTPException(status_code=503, detail=\"모델이 로드되지 않았습니다.\")\n",
    "    \n",
    "    if not request.texts:\n",
    "        raise HTTPException(status_code=400, detail=\"분석할 텍스트가 없습니다.\")\n",
    "    \n",
    "    if len(request.texts) > 100:  # 배치 크기 제한\n",
    "        raise HTTPException(status_code=400, detail=\"한 번에 최대 100개의 텍스트만 처리할 수 있습니다.\")\n",
    "    \n",
    "    try:\n",
    "        results = []\n",
    "        batch_predictions = predictor.predict_batch(request.texts)\n",
    "        \n",
    "        for text, (prediction, confidence, probability) in zip(request.texts, batch_predictions):\n",
    "            results.append(SentimentResponse(\n",
    "                text=text,\n",
    "                prediction=prediction,\n",
    "                confidence=confidence,\n",
    "                probability=probability\n",
    "            ))\n",
    "        \n",
    "        return BatchSentimentResponse(results=results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"배치 예측 중 오류: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=\"배치 예측 중 오류가 발생했습니다.\")\n",
    "\n",
    "@app.get(\"/model/info\")\n",
    "async def get_model_info():\n",
    "    \"\"\"모델 정보를 반환합니다.\"\"\"\n",
    "    if predictor is None:\n",
    "        raise HTTPException(status_code=503, detail=\"모델이 로드되지 않았습니다.\")\n",
    "    \n",
    "    return {\n",
    "        \"model_name\": \"감정 분석 MLP 모델\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"model_file\": os.path.basename(predictor.model_path),\n",
    "        \"vectorizer_file\": os.path.basename(predictor.vectorizer_path),\n",
    "        \"scaler_file\": os.path.basename(predictor.scaler_path),\n",
    "        \"total_parameters\": predictor.model.count_params(),\n",
    "        \"input_features\": predictor.model.input_shape[1],\n",
    "        \"classes\": [\"부정\", \"긍정\"],\n",
    "        \"description\": \"TF-IDF + MLP 기반 한국어 감정 분석 모델\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deed6cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Jupyter 환경 감지됨\n",
      "🚀 감정 분석 FastAPI 서버 시작! (Jupyter 모드)\n",
      "📍 주소: http://127.0.0.1:8000\n",
      "📖 API 문서: http://127.0.0.1:8000/docs\n",
      "🎭 웹 인터페이스: http://127.0.0.1:8000\n",
      "❤️ 상태 확인: http://127.0.0.1:8000/health\n",
      "\n",
      "서버를 중지하려면 Kernel -> Interrupt를 선택하세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [39752]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:__main__:모델 및 전처리기 로딩 중...\n",
      "INFO:__main__:모델 로드 완료: saved_models/sentiment_mlp_model_20250916_193146.keras\n",
      "INFO:__main__:TF-IDF 벡터라이저 로드 완료: saved_models/sentiment_mlp_model_20250916_193146_vectorizer.pkl\n",
      "INFO:__main__:표준화 스케일러 로드 완료: saved_models/sentiment_mlp_model_20250916_193146_scaler.pkl\n",
      "INFO:__main__:모든 컴포넌트 로드 완료!\n",
      "INFO:__main__:모델 초기화 완료!\n",
      "INFO:__main__:서버 시작 완료!\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:63646 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:63646 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:63646 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:63646 - \"POST /predict HTTP/1.1\" 200 OK\n",
      "\n",
      "🛑 서버 중지 요청됨\n"
     ]
    }
   ],
   "source": [
    "# Jupyter 노트북용 서버 실행 함수\n",
    "import asyncio\n",
    "import threading\n",
    "import time\n",
    "from contextlib import asynccontextmanager\n",
    "\n",
    "def run_server_jupyter(host: str = \"127.0.0.1\", port: int = 8000):\n",
    "    \"\"\"\n",
    "    Jupyter 노트북에서 FastAPI 서버를 실행합니다.\n",
    "    \n",
    "    Args:\n",
    "        host: 서버 호스트 (기본값: 127.0.0.1)\n",
    "        port: 서버 포트 (기본값: 8000)\n",
    "    \"\"\"\n",
    "    print(f\"🚀 감정 분석 FastAPI 서버 시작! (Jupyter 모드)\")\n",
    "    print(f\"📍 주소: http://{host}:{port}\")\n",
    "    print(f\"📖 API 문서: http://{host}:{port}/docs\")\n",
    "    print(f\"🎭 웹 인터페이스: http://{host}:{port}\")\n",
    "    print(f\"❤️ 상태 확인: http://{host}:{port}/health\")\n",
    "    print()\n",
    "    print(\"서버를 중지하려면 Kernel -> Interrupt를 선택하세요.\")\n",
    "    \n",
    "    # Jupyter에서 실행할 수 있도록 별도 스레드에서 서버 실행\n",
    "    def run_uvicorn():\n",
    "        import asyncio\n",
    "        import uvicorn\n",
    "        \n",
    "        # 새로운 이벤트 루프 생성\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        \n",
    "        config = uvicorn.Config(\n",
    "            app=app,\n",
    "            host=host,\n",
    "            port=port,\n",
    "            log_level=\"info\"\n",
    "        )\n",
    "        server = uvicorn.Server(config)\n",
    "        \n",
    "        try:\n",
    "            loop.run_until_complete(server.serve())\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n🛑 서버가 중지되었습니다.\")\n",
    "        finally:\n",
    "            loop.close()\n",
    "    \n",
    "    # 백그라운드 스레드에서 서버 실행\n",
    "    server_thread = threading.Thread(target=run_uvicorn, daemon=True)\n",
    "    server_thread.start()\n",
    "    \n",
    "    try:\n",
    "        # 메인 스레드는 서버 스레드가 살아있는 동안 대기\n",
    "        while server_thread.is_alive():\n",
    "            time.sleep(0.1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 서버 중지 요청됨\")\n",
    "    \n",
    "    return server_thread\n",
    "\n",
    "# 일반 Python 스크립트용 서버 실행 함수\n",
    "def run_server_script(host: str = \"127.0.0.1\", port: int = 8000, reload: bool = False):\n",
    "    \"\"\"\n",
    "    일반 Python 스크립트에서 FastAPI 서버를 실행합니다.\n",
    "    \n",
    "    Args:\n",
    "        host: 서버 호스트 (기본값: 127.0.0.1)\n",
    "        port: 서버 포트 (기본값: 8000)\n",
    "        reload: 코드 변경 시 자동 재시작 (기본값: False)\n",
    "    \"\"\"\n",
    "    print(f\"🚀 감정 분석 FastAPI 서버 시작!\")\n",
    "    print(f\"📍 주소: http://{host}:{port}\")\n",
    "    print(f\"📖 API 문서: http://{host}:{port}/docs\")\n",
    "    print(f\"🎭 웹 인터페이스: http://{host}:{port}\")\n",
    "    print(f\"❤️ 상태 확인: http://{host}:{port}/health\")\n",
    "    print()\n",
    "    print(\"서버를 중지하려면 Ctrl+C를 누르세요.\")\n",
    "    \n",
    "    uvicorn.run(\n",
    "        app,  # app 객체 직접 전달\n",
    "        host=host,\n",
    "        port=port,\n",
    "        reload=reload,\n",
    "        log_level=\"info\"\n",
    "    )\n",
    "\n",
    "# 환경 감지 및 적절한 실행 함수 선택\n",
    "def run_server(host: str = \"127.0.0.1\", port: int = 8000, reload: bool = False):\n",
    "    \"\"\"\n",
    "    환경을 자동 감지하여 적절한 방식으로 서버를 실행합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Jupyter 환경인지 확인\n",
    "        get_ipython()\n",
    "        print(\"🔍 Jupyter 환경 감지됨\")\n",
    "        return run_server_jupyter(host, port)\n",
    "    except NameError:\n",
    "        # 일반 Python 스크립트 환경\n",
    "        print(\"🔍 Python 스크립트 환경 감지됨\")\n",
    "        return run_server_script(host, port, reload)\n",
    "\n",
    "# 메인 실행부 (Jupyter에서는 사용하지 않음)\n",
    "if __name__ == \"__main__\":\n",
    "    # 서버 실행 (기본 설정)\n",
    "    run_server()\n",
    "    \n",
    "    # 다른 설정으로 실행하려면:\n",
    "    # run_server(host=\"0.0.0.0\", port=8080, reload=True)  # 외부 접근 허용, 포트 8080, 자동 재시작\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a420de",
   "metadata": {},
   "source": [
    "# 🚀 FastAPI 감정 분석 웹서버 사용 가이드\n",
    "\n",
    "## 📋 개요\n",
    "003-03.ipynb에서 훈련하고 저장한 MLP 감정 분석 모델을 사용하는 FastAPI 웹서버입니다.\n",
    "\n",
    "## 🛠️ 설치 및 실행\n",
    "\n",
    "### 1. 필요한 패키지 설치\n",
    "```bash\n",
    "pip install fastapi uvicorn tensorflow scikit-learn pandas numpy\n",
    "```\n",
    "\n",
    "### 2. 서버 실행 방법\n",
    "\n",
    "#### 방법 1: Jupyter 노트북에서 직접 실행\n",
    "위의 모든 셀을 순서대로 실행한 후, 마지막 셀을 실행하면 서버가 시작됩니다.\n",
    "\n",
    "#### 방법 2: Python 스크립트로 저장하여 실행\n",
    "노트북을 `.py` 파일로 내보낸 후 터미널에서 실행:\n",
    "```bash\n",
    "python sentiment_api.py\n",
    "```\n",
    "\n",
    "#### 방법 3: uvicorn으로 직접 실행\n",
    "```bash\n",
    "uvicorn main:app --host 127.0.0.1 --port 8000 --reload\n",
    "```\n",
    "\n",
    "## 🌐 API 엔드포인트\n",
    "\n",
    "### 메인 페이지\n",
    "- **URL**: `http://127.0.0.1:8000/`\n",
    "- **설명**: 웹 브라우저에서 직접 텍스트를 입력하여 감정 분석 가능\n",
    "\n",
    "### 단일 텍스트 분석\n",
    "- **URL**: `POST http://127.0.0.1:8000/predict`\n",
    "- **요청 형식**:\n",
    "```json\n",
    "{\n",
    "    \"text\": \"정말 맛있어요! 최고입니다!\"\n",
    "}\n",
    "```\n",
    "- **응답 형식**:\n",
    "```json\n",
    "{\n",
    "    \"text\": \"정말 맛있어요! 최고입니다!\",\n",
    "    \"prediction\": \"긍정\",\n",
    "    \"confidence\": 0.999,\n",
    "    \"probability\": 0.999\n",
    "}\n",
    "```\n",
    "\n",
    "### 배치 텍스트 분석\n",
    "- **URL**: `POST http://127.0.0.1:8000/predict/batch`\n",
    "- **요청 형식**:\n",
    "```json\n",
    "{\n",
    "    \"texts\": [\n",
    "        \"정말 맛있어요!\",\n",
    "        \"서비스가 별로네요...\",\n",
    "        \"가격 대비 괜찮아요\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "### 모델 정보\n",
    "- **URL**: `GET http://127.0.0.1:8000/model/info`\n",
    "- **설명**: 로드된 모델의 상세 정보 조회\n",
    "\n",
    "### 상태 확인\n",
    "- **URL**: `GET http://127.0.0.1:8000/health`\n",
    "- **설명**: 서버 및 모델 로드 상태 확인\n",
    "\n",
    "### API 문서\n",
    "- **URL**: `http://127.0.0.1:8000/docs`\n",
    "- **설명**: 자동 생성된 Swagger UI API 문서\n",
    "\n",
    "## 🧪 테스트 예시\n",
    "\n",
    "### curl을 사용한 테스트\n",
    "```bash\n",
    "# 단일 텍스트 분석\n",
    "curl -X POST \"http://127.0.0.1:8000/predict\" \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"text\": \"정말 맛있어요!\"}'\n",
    "\n",
    "# 상태 확인\n",
    "curl -X GET \"http://127.0.0.1:8000/health\"\n",
    "```\n",
    "\n",
    "### Python requests를 사용한 테스트\n",
    "```python\n",
    "import requests\n",
    "\n",
    "# 단일 예측\n",
    "response = requests.post(\n",
    "    \"http://127.0.0.1:8000/predict\",\n",
    "    json={\"text\": \"정말 맛있어요!\"}\n",
    ")\n",
    "print(response.json())\n",
    "\n",
    "# 배치 예측\n",
    "response = requests.post(\n",
    "    \"http://127.0.0.1:8000/predict/batch\",\n",
    "    json={\"texts\": [\"좋아요!\", \"별로네요...\"]}\n",
    ")\n",
    "print(response.json())\n",
    "```\n",
    "\n",
    "## ⚠️ 주의사항\n",
    "1. **모델 파일 위치**: `saved_models/` 디렉토리에 003-03.ipynb에서 저장한 모델 파일들이 있어야 합니다.\n",
    "2. **메모리 사용량**: TensorFlow 모델이 로드되므로 충분한 메모리가 필요합니다.\n",
    "3. **포트 충돌**: 8000번 포트가 사용 중인 경우 다른 포트를 사용하세요.\n",
    "\n",
    "## 🔧 문제 해결\n",
    "- **모델 로드 실패**: 003-03.ipynb를 먼저 실행하여 모델을 저장했는지 확인\n",
    "- **포트 사용 중**: `run_server(port=8080)` 등으로 다른 포트 사용\n",
    "- **메모리 부족**: 다른 프로그램을 종료하고 재시도\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d26238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서버 실행 (이 셀을 실행하면 FastAPI 서버가 시작됩니다)\n",
    "# 주의: 이 셀을 실행하면 서버가 시작되고 셀이 계속 실행 상태를 유지합니다.\n",
    "# 서버를 중지하려면 Kernel -> Interrupt를 선택하세요.\n",
    "\n",
    "print(\"🔧 서버 실행 준비 중...\")\n",
    "print(\"📁 모델 파일 확인 중...\")\n",
    "\n",
    "# 모델 파일 존재 확인\n",
    "model_dir = \"saved_models\"\n",
    "model_name = \"sentiment_mlp_model_20250916_193146\"\n",
    "\n",
    "model_files = [\n",
    "    f\"{model_name}.keras\",\n",
    "    f\"{model_name}_vectorizer.pkl\", \n",
    "    f\"{model_name}_scaler.pkl\"\n",
    "]\n",
    "\n",
    "missing_files = []\n",
    "for file in model_files:\n",
    "    file_path = os.path.join(model_dir, file)\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"✅ {file}\")\n",
    "    else:\n",
    "        print(f\"❌ {file}\")\n",
    "        missing_files.append(file)\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\n⚠️ 누락된 파일들: {missing_files}\")\n",
    "    print(\"💡 003-03.ipynb를 먼저 실행하여 모델을 저장해주세요.\")\n",
    "else:\n",
    "    print(f\"\\n🎉 모든 모델 파일이 준비되었습니다!\")\n",
    "    print(\"🚀 FastAPI 서버를 시작합니다...\")\n",
    "    print()\n",
    "    \n",
    "    # 서버 실행 (Jupyter 환경 자동 감지)\n",
    "    try:\n",
    "        server_thread = run_server(host=\"127.0.0.1\", port=8000)\n",
    "        print(\"\\n✅ 서버가 백그라운드에서 실행 중입니다!\")\n",
    "        print(\"🌐 브라우저에서 http://127.0.0.1:8000 에 접속하세요!\")\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 서버가 중지되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 서버 실행 중 오류 발생: {e}\")\n",
    "        print(\"💡 문제 해결 방법:\")\n",
    "        print(\"   1. 포트가 이미 사용 중인 경우: run_server(port=8080)\")\n",
    "        print(\"   2. 모델 파일이 없는 경우: 003-03.ipynb를 먼저 실행\")\n",
    "        print(\"   3. 패키지가 없는 경우: pip install -r requirements.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4fd624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서버 상태 확인 및 테스트 함수들\n",
    "\n",
    "def check_server_status(host=\"127.0.0.1\", port=8000):\n",
    "    \"\"\"서버가 실행 중인지 확인합니다.\"\"\"\n",
    "    import requests\n",
    "    try:\n",
    "        response = requests.get(f\"http://{host}:{port}/health\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"✅ 서버가 정상 실행 중입니다! (http://{host}:{port})\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"⚠️ 서버 응답 오류: {response.status_code}\")\n",
    "            return False\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ 서버에 연결할 수 없습니다: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_sentiment_api(text=\"정말 맛있어요!\", host=\"127.0.0.1\", port=8000):\n",
    "    \"\"\"감정 분석 API를 테스트합니다.\"\"\"\n",
    "    import requests\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"http://{host}:{port}/predict\",\n",
    "            json={\"text\": text},\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"📝 입력: \\\"{text}\\\"\")\n",
    "            print(f\"🎯 예측: {result['prediction']}\")\n",
    "            print(f\"📊 신뢰도: {result['confidence']:.3f}\")\n",
    "            print(f\"📈 확률: {result['probability']:.3f}\")\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"❌ API 오류: {response.status_code}\")\n",
    "            print(f\"오류 내용: {response.text}\")\n",
    "            return None\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ API 요청 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "# 사용 예시:\n",
    "# check_server_status()  # 서버 상태 확인\n",
    "# test_sentiment_api(\"정말 맛있어요!\")  # 감정 분석 테스트\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
