{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa01296",
   "metadata": {},
   "source": [
    "# MNIST 필기체 분류 - LeNet-5 CNN 모델\n",
    "\n",
    "이 노트북에서는 LeNet-5 아키텍처를 사용하여 MNIST 필기체 숫자를 분류하는 CNN 모델을 구현합니다.\n",
    "\n",
    "## LeNet-5 아키텍처 개요\n",
    "![](./lenet-5.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 import\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
    "print(f\"Keras 버전: {keras.__version__}\")\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "print(f\"GPU 사용 가능: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# 재현 가능한 결과를 위한 시드 설정\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00ea4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터셋 로드\n",
    "print(\"MNIST 데이터셋 로딩 중...\")\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"훈련 데이터 형태: {x_train.shape}\")\n",
    "print(f\"훈련 레이블 형태: {y_train.shape}\")\n",
    "print(f\"테스트 데이터 형태: {x_test.shape}\")\n",
    "print(f\"테스트 레이블 형태: {y_test.shape}\")\n",
    "\n",
    "# 데이터 타입 확인\n",
    "print(f\"픽셀 값 범위: {x_train.min()} ~ {x_train.max()}\")\n",
    "print(f\"레이블 클래스: {np.unique(y_train)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e68163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 이미지 시각화\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.title(f'레이블: {y_train[i]}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('MNIST 훈련 데이터 샘플', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 클래스 분포 확인\n",
    "plt.figure(figsize=(10, 6))\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "plt.title('MNIST 훈련 데이터의 클래스 분포')\n",
    "plt.xlabel('숫자 클래스')\n",
    "plt.ylabel('샘플 개수')\n",
    "plt.xticks(unique)\n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(i, count + 100, str(count), ha='center')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786f45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "print(\"데이터 전처리 중...\")\n",
    "\n",
    "# 1. 정규화 (0-255 → 0-1)\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# 2. 28x28 → 32x32로 패딩 (LeNet-5는 32x32 입력을 사용)\n",
    "x_train = tf.pad(x_train, [[0, 0], [2, 2], [2, 2]], mode='CONSTANT')\n",
    "x_test = tf.pad(x_test, [[0, 0], [2, 2], [2, 2]], mode='CONSTANT')\n",
    "\n",
    "# 3. 채널 차원 추가 (grayscale)\n",
    "x_train = tf.expand_dims(x_train, axis=-1)\n",
    "x_test = tf.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# 4. 레이블을 원-핫 인코딩\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"전처리 후 훈련 데이터 형태: {x_train.shape}\")\n",
    "print(f\"전처리 후 테스트 데이터 형태: {x_test.shape}\")\n",
    "print(f\"전처리 후 훈련 레이블 형태: {y_train.shape}\")\n",
    "print(f\"전처리 후 테스트 레이블 형태: {y_test.shape}\")\n",
    "print(f\"픽셀 값 범위: {x_train.numpy().min():.3f} ~ {x_train.numpy().max():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa13e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 이미지 확인\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.imshow(x_train[i].numpy().squeeze(), cmap='gray')\n",
    "    plt.title(f'32x32 패딩된 이미지\\n레이블: {np.argmax(y_train[i])}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('전처리된 MNIST 이미지 (32x32)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9588886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5 모델 구현\n",
    "def create_lenet5():\n",
    "    \"\"\"\n",
    "    LeNet-5 아키텍처를 구현하는 함수\n",
    "    \n",
    "    원본 LeNet-5 구조:\n",
    "    - 입력: 32x32x1\n",
    "    - C1: 6개의 5x5 컨볼루션 (28x28x6)\n",
    "    - S2: 2x2 평균 풀링 (14x14x6) → MaxPooling 사용\n",
    "    - C3: 16개의 5x5 컨볼루션 (10x10x16)\n",
    "    - S4: 2x2 평균 풀링 (5x5x16) → MaxPooling 사용\n",
    "    - C5: 120개의 5x5 컨볼루션 → Dense(120)으로 구현\n",
    "    - F6: 84개의 완전연결층\n",
    "    - 출력: 10개의 클래스\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # 입력층\n",
    "        layers.Input(shape=(32, 32, 1)),\n",
    "        \n",
    "        # C1: 첫 번째 컨볼루션 층 (6개의 5x5 필터)\n",
    "        layers.Conv2D(filters=6, kernel_size=5, activation='tanh', name='C1'),\n",
    "        \n",
    "        # S2: 첫 번째 풀링 층 (2x2 맥스풀링)\n",
    "        layers.MaxPooling2D(pool_size=2, strides=2, name='S2'),\n",
    "        \n",
    "        # C3: 두 번째 컨볼루션 층 (16개의 5x5 필터)\n",
    "        layers.Conv2D(filters=16, kernel_size=5, activation='tanh', name='C3'),\n",
    "        \n",
    "        # S4: 두 번째 풀링 층 (2x2 맥스풀링)\n",
    "        layers.MaxPooling2D(pool_size=2, strides=2, name='S4'),\n",
    "        \n",
    "        # 평탄화\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        # C5: 세 번째 완전연결층 (120개 뉴런)\n",
    "        layers.Dense(120, activation='tanh', name='C5'),\n",
    "        \n",
    "        # F6: 네 번째 완전연결층 (84개 뉴런)\n",
    "        layers.Dense(84, activation='tanh', name='F6'),\n",
    "        \n",
    "        # 출력층: 10개 클래스 (softmax 활성화)\n",
    "        layers.Dense(10, activation='softmax', name='Output')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 모델 생성\n",
    "print(\"LeNet-5 모델 생성 중...\")\n",
    "model = create_lenet5()\n",
    "\n",
    "# 모델 구조 출력\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef077185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 아키텍처 시각화\n",
    "try:\n",
    "    keras.utils.plot_model(\n",
    "        model, \n",
    "        to_file='lenet5_architecture.png',\n",
    "        show_shapes=True, \n",
    "        show_layer_names=True,\n",
    "        rankdir='TB'\n",
    "    )\n",
    "    from IPython.display import Image\n",
    "    Image('lenet5_architecture.png')\n",
    "except:\n",
    "    print(\"모델 시각화를 위해서는 graphviz와 pydot이 필요합니다.\")\n",
    "    print(\"pip install graphviz pydot 으로 설치할 수 있습니다.\")\n",
    "\n",
    "# 파라미터 수 계산\n",
    "total_params = model.count_params()\n",
    "print(f\"\\n총 파라미터 수: {total_params:,}\")\n",
    "\n",
    "# 각 층별 출력 크기 확인\n",
    "print(\"\\n각 층별 출력 크기:\")\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"{i+1}. {layer.name}: {layer.output_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c7e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "print(\"모델 컴파일 중...\")\n",
    "model.compile(\n",
    "    optimizer='adam',  # 원래 LeNet-5는 SGD를 사용했지만, Adam이 더 효율적\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 콜백 함수 정의\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"컴파일 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75311c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "print(\"모델 훈련 시작...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 훈련 파라미터\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "# 훈련 실행\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"훈련 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d874f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 과정 시각화\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['accuracy'], label='훈련 정확도', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='검증 정확도', linewidth=2)\n",
    "plt.title('모델 정확도')\n",
    "plt.xlabel('에포크')\n",
    "plt.ylabel('정확도')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['loss'], label='훈련 손실', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='검증 손실', linewidth=2)\n",
    "plt.title('모델 손실')\n",
    "plt.xlabel('에포크')\n",
    "plt.ylabel('손실')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 학습률 그래프 (있는 경우)\n",
    "plt.subplot(1, 3, 3)\n",
    "if 'lr' in history.history:\n",
    "    plt.plot(history.history['lr'], linewidth=2)\n",
    "    plt.title('학습률 변화')\n",
    "    plt.xlabel('에포크')\n",
    "    plt.ylabel('학습률')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, '학습률 정보 없음', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "    plt.title('학습률')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 최종 훈련 결과 출력\n",
    "final_train_acc = max(history.history['accuracy'])\n",
    "final_val_acc = max(history.history['val_accuracy'])\n",
    "final_train_loss = min(history.history['loss'])\n",
    "final_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "print(f\"최고 훈련 정확도: {final_train_acc:.4f}\")\n",
    "print(f\"최고 검증 정확도: {final_val_acc:.4f}\")\n",
    "print(f\"최소 훈련 손실: {final_train_loss:.4f}\")\n",
    "print(f\"최소 검증 손실: {final_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터로 모델 평가\n",
    "print(\"테스트 데이터로 모델 평가 중...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"테스트 손실: {test_loss:.4f}\")\n",
    "print(f\"테스트 정확도: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# 예측 수행\n",
    "print(\"\\n예측 수행 중...\")\n",
    "y_pred = model.predict(x_test, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 분류 보고서\n",
    "print(\"\\n분류 보고서:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, \n",
    "                          target_names=[str(i) for i in range(10)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c1864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동 행렬 시각화\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 혼동 행렬 (숫자)\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "plt.title('혼동 행렬 (개수)')\n",
    "plt.xlabel('예측된 클래스')\n",
    "plt.ylabel('실제 클래스')\n",
    "\n",
    "# 혼동 행렬 (비율)\n",
    "plt.subplot(1, 2, 2)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues',\n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "plt.title('혼동 행렬 (비율)')\n",
    "plt.xlabel('예측된 클래스')\n",
    "plt.ylabel('실제 클래스')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 클래스별 정확도\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "print(\"\\n클래스별 정확도:\")\n",
    "for i, acc in enumerate(class_accuracy):\n",
    "    print(f\"숫자 {i}: {acc:.4f} ({acc*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa92b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과 시각화\n",
    "def plot_predictions(images, true_labels, pred_labels, pred_probs, num_samples=16):\n",
    "    \"\"\"예측 결과를 시각화하는 함수\"\"\"\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        \n",
    "        # 이미지 표시 (패딩 제거)\n",
    "        img = images[i].squeeze()[2:30, 2:30]  # 32x32에서 28x28로 복원\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        \n",
    "        # 예측 결과 색상 설정\n",
    "        color = 'green' if true_labels[i] == pred_labels[i] else 'red'\n",
    "        \n",
    "        plt.title(f'실제: {true_labels[i]}, 예측: {pred_labels[i]}\\n'\n",
    "                 f'확신도: {pred_probs[i]:.3f}', color=color, fontsize=10)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('LeNet-5 예측 결과 (녹색: 정답, 빨강: 오답)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 랜덤 샘플 선택\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(len(x_test), 16, replace=False)\n",
    "\n",
    "sample_images = x_test[sample_indices]\n",
    "sample_true = y_true_classes[sample_indices]\n",
    "sample_pred = y_pred_classes[sample_indices]\n",
    "sample_probs = np.max(y_pred[sample_indices], axis=1)\n",
    "\n",
    "plot_predictions(sample_images, sample_true, sample_pred, sample_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2324ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오분류 사례 분석\n",
    "misclassified_indices = np.where(y_true_classes != y_pred_classes)[0]\n",
    "print(f\"총 오분류 개수: {len(misclassified_indices)}\")\n",
    "print(f\"오분류율: {len(misclassified_indices)/len(y_test)*100:.2f}%\")\n",
    "\n",
    "# 오분류 사례 중 일부 시각화\n",
    "if len(misclassified_indices) > 0:\n",
    "    # 가장 확신도가 높은 오분류 사례들 선택\n",
    "    misclassified_probs = np.max(y_pred[misclassified_indices], axis=1)\n",
    "    top_confident_wrong = misclassified_indices[np.argsort(misclassified_probs)[-16:]]\n",
    "    \n",
    "    plt.figure(figsize=(16, 12))\n",
    "    for i, idx in enumerate(top_confident_wrong):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        \n",
    "        # 이미지 표시 (패딩 제거)\n",
    "        img = x_test[idx].squeeze()[2:30, 2:30]\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        \n",
    "        true_label = y_true_classes[idx]\n",
    "        pred_label = y_pred_classes[idx]\n",
    "        confidence = np.max(y_pred[idx])\n",
    "        \n",
    "        plt.title(f'실제: {true_label}, 예측: {pred_label}\\n확신도: {confidence:.3f}', \n",
    "                 color='red', fontsize=10)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('가장 확신도가 높은 오분류 사례들', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"모든 예측이 정확합니다!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ce6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model_save_path = 'lenet5_mnist_model.keras'\n",
    "model.save(model_save_path)\n",
    "print(f\"모델이 '{model_save_path}'에 저장되었습니다.\")\n",
    "\n",
    "# 결과 요약\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LeNet-5 MNIST 분류 모델 결과 요약\")\n",
    "print(\"=\"*60)\n",
    "print(f\"모델 아키텍처: LeNet-5 (1998년 Yann LeCun)\")\n",
    "print(f\"데이터셋: MNIST (60,000 훈련, 10,000 테스트)\")\n",
    "print(f\"입력 크기: 32x32x1 (28x28 MNIST를 패딩)\")\n",
    "print(f\"총 파라미터: {total_params:,}\")\n",
    "print(f\"훈련 에포크: {len(history.history['accuracy'])}\")\n",
    "print(f\"배치 크기: {BATCH_SIZE}\")\n",
    "print(f\"옵티마이저: Adam\")\n",
    "print(\"-\"*60)\n",
    "print(f\"최종 테스트 정확도: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"최종 테스트 손실: {test_loss:.4f}\")\n",
    "print(f\"총 오분류 개수: {len(misclassified_indices):,}\")\n",
    "print(f\"오분류율: {len(misclassified_indices)/len(y_test)*100:.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 클래스별 성능 요약\n",
    "print(\"\\n클래스별 성능 요약:\")\n",
    "for i in range(10):\n",
    "    class_acc = class_accuracy[i]\n",
    "    class_total = cm.sum(axis=1)[i]\n",
    "    class_correct = cm[i, i]\n",
    "    print(f\"숫자 {i}: {class_correct:,}/{class_total:,} = {class_acc:.4f} ({class_acc*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n모델 훈련 및 평가가 완료되었습니다!\")\n",
    "print(f\"LeNet-5는 MNIST 데이터에서 {test_accuracy*100:.2f}%의 정확도를 달성했습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
